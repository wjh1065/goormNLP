{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[HW1.1]PytorchTutorial.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR26RFkwXtvi"
      },
      "source": [
        "# **[HW1.1] PyTorch Tutorial**\n",
        "1. Install packages\n",
        "2. Tensor\n",
        "3. AutoGrad\n",
        "\n",
        "딥러닝 실습은, 수업시간에 배웠던 개념들을 직접 코드로 옮겨보며 이를 폭넓게 이해하는 데에 초점을 맞추고 있습니다. 실습에서 사용한 예시 외에도, 다양한 architecture를 직접 구성해보며 각 node와 function의 역할을 명확히 이해해보시길 바랍니다.\n",
        "\n",
        "이번 실습에서는 딥러닝 모델을 만들때 사용하는 PyTorch library에 대한 기본 개념들을 익혀보도록 하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4iquuOQj1g9"
      },
      "source": [
        "# 1. Import packages\n",
        "\n",
        "> 필요한 package를 설치하고 import합니다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpvlE_XOWS33"
      },
      "source": [
        "런타임의 유형을 변경해줍니다.\n",
        "\n",
        "상단 메뉴에서 [런타임]->[런타임유형변경]->[하드웨어가속기]->[GPU]\n",
        "\n",
        "변경 이후 아래의 cell을 실행 시켰을 때, torch.cuda.is_avialable()이 True가 나와야 합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqVdEuPQzMAH",
        "outputId": "64bb1825-ce65-44ed-ed6b-c3349f1bab1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.10.0+cu111\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2o3-HPdHLZma"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "\n",
        "np.set_printoptions(precision=3)\n",
        "np.set_printoptions(suppress=True)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMkIJgfEl9kD"
      },
      "source": [
        "# 2. Tensor operations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxQqLw-Dl_Zw"
      },
      "source": [
        "텐서(tensor)는 배열(array)이나 행렬(matrix)과 매우 유사한 특수한 자료구조입니다. PyTorch에서는 텐서를 사용하여 모델의 입력과 출력뿐만 아니라 모델의 파라미터를 나타냅니다.\n",
        "\n",
        "GPU나 다른 연산 가속을 위한 특수한 하드웨어에서 실행할 수 있다는 점을 제외하면, 텐서는 NumPy의 ndarray와 매우 유사합니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8XqtZa8sXsw"
      },
      "source": [
        "##텐서 초기화하기\n",
        "\n",
        "데이터로부터 직접 생성하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCnmrA9ltYs0",
        "outputId": "2c45a160-285f-4351-ee2a-fd0b15f32087",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data = [[1, 2],[3, 4]]\n",
        "x = torch.tensor(data)\n",
        "x"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZx51U6fUXSc"
      },
      "source": [
        "Numpy array로부터 생성하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5m4qus2UnoL",
        "outputId": "164da21c-5e73-41ed-df28-d220738a9fb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np_array = np.array(data)\n",
        "x = torch.from_numpy(np_array)\n",
        "x"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BfwipaTYEFI"
      },
      "source": [
        "Tensor에서 Numpy array로 변환하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upkEJ9mBMCOd",
        "outputId": "f2e1d197-5955-4f27-e3d8-37b11c29afc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x.numpy()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2],\n",
              "       [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obZ-A5rxYOSx"
      },
      "source": [
        "다른 텐서와 같은 모양의 텐서 초기화하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkJRGOaEyyc0",
        "outputId": "23be1405-2aa7-48f8-9553-dade180a51cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_ones = torch.ones_like(x) # x_data의 속성을 유지합니다.\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "x_rand = torch.rand_like(x, dtype=torch.float) # x_data의 속성을 덮어씁니다.\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ones Tensor: \n",
            " tensor([[1, 1],\n",
            "        [1, 1]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.1584, 0.8348],\n",
            "        [0.7667, 0.7701]]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1E5bEPHZskg"
      },
      "source": [
        "주어진 shape으로 초기화하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pk1OASeazKtN",
        "outputId": "4afb819a-a9b1-4b58-80db-16745927387c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "shape = (3,4)\n",
        "rand_tensor = torch.rand(shape)\n",
        "ones_tensor = torch.ones(shape)\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "\n",
        "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
        "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Tensor: \n",
            " tensor([[0.6210, 0.5000, 0.4839, 0.8121],\n",
            "        [0.8048, 0.1308, 0.2244, 0.6561],\n",
            "        [0.3970, 0.3898, 0.4084, 0.9355]]) \n",
            "\n",
            "Ones Tensor: \n",
            " tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]]) \n",
            "\n",
            "Zeros Tensor: \n",
            " tensor([[0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zB-u3e9taDjT"
      },
      "source": [
        "## 텐서의 속성\n",
        "\n",
        "텐서의 속성은 텐서의 모양(shape), 자료형(datatype) 및 어느 장치에 저장되는지를 나타냅니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HWWRcNjaLDi",
        "outputId": "43faa259-962d-4274-fe58-ba74841239f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tensor = torch.rand(3,4)\n",
        "\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A7LymV5aYEA"
      },
      "source": [
        "아래와 같이 cpu에 할당되어 있는 tensor를 gpu에 옮길 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKvYqt3ZaOXZ",
        "outputId": "f3e23e3f-6120-47f3-acd4-974c4593e9fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "device = torch.device('cuda')\n",
        "tensor = tensor.to(device)\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device tensor is stored on: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01vssH7n24cq"
      },
      "source": [
        "## 텐서 연산"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqON2YtYczmS"
      },
      "source": [
        "Numpy식의 인덱싱과 슬라이싱"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOv_w4LhjTDq",
        "outputId": "3d7366f7-c252-4b4d-ae49-99344d907653",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tensor = torch.ones(3, 4)\n",
        "tensor[:,1] = 0\n",
        "print(tensor)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR0J9p1WkpHO"
      },
      "source": [
        "텐서 합치기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s68HmhqlknkX",
        "outputId": "98648550-e681-4343-a5fc-785b84e164ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "t1 = torch.cat([tensor, tensor, tensor], dim=0)\n",
        "print(t1)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYxrFYAjbQuS",
        "outputId": "10dfd3a1-2a02-495e-8f05-f3874911a22d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
        "print(t1)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThLzN1ONbV-p"
      },
      "source": [
        "텐서 곱하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCMMXj8ejXVG",
        "outputId": "8d42bed8-0574-44fd-a19a-ee2cd18d6132",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 요소별 곱(element-wise product)을 계산합니다\n",
        "print(f\"tensor.mul(tensor) \\n {tensor.mul(tensor)} \\n\")\n",
        "\n",
        "# 다른 문법:\n",
        "print(f\"tensor * tensor \\n {tensor * tensor}\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor.mul(tensor) \n",
            " tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]]) \n",
            "\n",
            "tensor * tensor \n",
            " tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9752P1u90enu"
      },
      "source": [
        "텐서간 matrix multiplication 진행하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhOPv757T4NG",
        "outputId": "8012c0dc-7155-428d-aa3a-b1f0932769f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(f\"tensor.matmul(tensor.T) \\n {tensor.matmul(tensor.T)} \\n\")\n",
        "# 다른 문법:\n",
        "print(f\"tensor @ tensor.T \\n {tensor @ tensor.T}\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor.matmul(tensor.T) \n",
            " tensor([[3., 3., 3.],\n",
            "        [3., 3., 3.],\n",
            "        [3., 3., 3.]]) \n",
            "\n",
            "tensor @ tensor.T \n",
            " tensor([[3., 3., 3.],\n",
            "        [3., 3., 3.],\n",
            "        [3., 3., 3.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sC_i0POOIf0M"
      },
      "source": [
        "# 3. AUTOGRAD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tQLTW4vcRJK"
      },
      "source": [
        "PyTorch에는 torch.autograd라고 불리는 자동 미분 엔진이 내장되어 있습니다. \n",
        "이는 모든 node에 대한 미분 값을 자동으로 계산해주게 됩니다.\n",
        "\n",
        "입력 X, 파라미터 W , 그리고 cross-entropy loss를 사용하는 logistic regression model의 gradient를 autograd를 이용해서 구해보도록 하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-b3w8_NGdCL1"
      },
      "source": [
        "## 입력 및 파라미터 초기화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52zAKX7zLl7n",
        "outputId": "48a87e2e-cb5b-4045-efb5-0d4d18655153",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x = torch.ones(5)  # input tensor\n",
        "y = torch.zeros(3)  # expected output\n",
        "w = torch.randn(5, 3, requires_grad=True)\n",
        "b = torch.randn(3, requires_grad=True)\n",
        "print(x)\n",
        "print(y)\n",
        "print(w)\n",
        "print(b)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n",
            "tensor([0., 0., 0.])\n",
            "tensor([[-0.5675,  0.9924,  0.2273],\n",
            "        [-1.2881,  0.1123,  1.3864],\n",
            "        [-1.7792, -0.6308,  0.4361],\n",
            "        [-0.8531, -0.8727, -2.5739],\n",
            "        [-2.1294, -1.5781, -0.6698]], requires_grad=True)\n",
            "tensor([-0.9114,  0.4530, -0.6197], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfSzTTVUeb06"
      },
      "source": [
        "## Forward"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09v6hrSIecG-",
        "outputId": "79ce087f-a983-49cb-a518-9c80af03c383",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "z = torch.matmul(x,w)+b\n",
        "z"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-7.5287, -1.5240, -1.8136], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1R19jHY9Pemt"
      },
      "source": [
        "## Loss Function\n",
        "\n",
        "PyTorch에서는 node를 크게 2가지의 방법의 api를 활용해서 사용합니다.\n",
        "\n",
        "1. [torch.nn](https://pytorch.org/docs/stable/nn.html)\n",
        "2. [torch.nn.functional](https://pytorch.org/docs/stable/nn.functional.html)\n",
        "\n",
        "torch.nn은 사전에 node를 초기화 시켜놓고, 해당 node에 텐서를 통과시켜 값을 받는 형태인 반면, torch.nn.functional은 사전에 초기화없이 바로 함수처럼 사용하는 방식입니다.\n",
        "\n",
        "코딩 스타일에 맞춰 원하시는 api를 선택하셔서 사용하시면 됩니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TQe1Nw8QLMu",
        "outputId": "f4d13f7f-7ab6-4777-aa0f-055ef73d6037",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "loss = loss_fn(z, y)\n",
        "loss"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1162, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gihsaH3ULCRN",
        "outputId": "3901b45b-5945-4465-dbaa-4f6746250050",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)\n",
        "loss"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1162, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCsd5yep3-sj"
      },
      "source": [
        "## Backward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfNejCDye61c"
      },
      "source": [
        "모델에서 매개변수의 가중치를 최적화하려면 파라미터에 대한 loss function의 도함수(derivative)를 계산해야 합니다. \n",
        "이러한 도함수를 계산하기 위해, loss.backward() 를 호출한 다음 w.grad와 b.grad에서 값을 가져옵니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OptZdnLSu5vC",
        "outputId": "95579359-6fcd-4df6-a059-a7b5aa2d35b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "loss.backward()\n",
        "print(x.grad)\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "tensor([[0.0002, 0.0596, 0.0467],\n",
            "        [0.0002, 0.0596, 0.0467],\n",
            "        [0.0002, 0.0596, 0.0467],\n",
            "        [0.0002, 0.0596, 0.0467],\n",
            "        [0.0002, 0.0596, 0.0467]])\n",
            "tensor([0.0002, 0.0596, 0.0467])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFE4lc-lfYtf"
      },
      "source": [
        "기본적으로, requires_grad=True인 모든 텐서들은 연산 기록을 추적하고 미분 계산을 지원합니다. 그러나 모델을 학습한 뒤 입력 데이터를 단순히 적용하기만 하는 경우와 같이 forward 연산만 필요한 경우에는, 미분 연산을 위한 값들을 저장해두는 것이 속력 및 메모리의 저하를 가져올 수 있습니다. 연산 코드를 torch.no_grad() 블록으로 둘러싸서 미분 추적을 멈출 수 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaiqxruWT_so",
        "outputId": "3e258ca6-4c1e-4416-aa2f-f213977d92c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "z = torch.matmul(x, w)+b\n",
        "print(z.requires_grad)\n",
        "\n",
        "with torch.no_grad():\n",
        "    z = torch.matmul(x, w)+b\n",
        "print(z.requires_grad)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_NqQRDaKqU6"
      },
      "source": [
        "# Reference\n",
        "\n",
        "1. https://tutorials.pytorch.kr/index.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6uX96q05Ddha"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[HW30] Sub-word Tokenization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "961c0ac8c25949218f8e52c4be6f8123": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d4b20bb9be864d10beabad038d8df23c",
              "IPY_MODEL_9908a709076c479183e9457ab199ca8f",
              "IPY_MODEL_528248a7e0d24d50852e7167b9bdb6f6"
            ],
            "layout": "IPY_MODEL_047898783c5a4dbc80a77f2505656fa8"
          }
        },
        "d4b20bb9be864d10beabad038d8df23c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c263236ed5524bc5986ac446bdcc2073",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6d619529fe3e47eb84461cf6ba89d7e2",
            "value": "Downloading: 100%"
          }
        },
        "9908a709076c479183e9457ab199ca8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_807a3da61af44ae48c6649f3d90f38e8",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_08781f1880834f73b147d582ee53ffb0",
            "value": 213450
          }
        },
        "528248a7e0d24d50852e7167b9bdb6f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a5a6e93d1784ac395e588ca7a0e8dec",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b4e0708ff88946e2928002506df1dbb1",
            "value": " 208k/208k [00:00&lt;00:00, 9.62kB/s]"
          }
        },
        "047898783c5a4dbc80a77f2505656fa8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c263236ed5524bc5986ac446bdcc2073": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d619529fe3e47eb84461cf6ba89d7e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "807a3da61af44ae48c6649f3d90f38e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08781f1880834f73b147d582ee53ffb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a5a6e93d1784ac395e588ca7a0e8dec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4e0708ff88946e2928002506df1dbb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22f02c53f39c4f00940c5f9ac2fd2cd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_868c42721968460ba5f898857582dce0",
              "IPY_MODEL_37d067cca40444fe8768b90793a405c6",
              "IPY_MODEL_9818b6c7fda145938d545f01450a776f"
            ],
            "layout": "IPY_MODEL_fe733235efed485b8f4ed5324e23d6dc"
          }
        },
        "868c42721968460ba5f898857582dce0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14df01630ac2484eb84c91f13a808eca",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f4363879cdd04f6a857e97e233231434",
            "value": "Downloading: 100%"
          }
        },
        "37d067cca40444fe8768b90793a405c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56be7eda2ff3436ca1d3a05c0ee90ceb",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe4c5844930e44de9630fc55224789a0",
            "value": 29
          }
        },
        "9818b6c7fda145938d545f01450a776f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fc68d703ca34da6a9c0ab3668d28e3a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3175deb5c7dd469d8fda0ce5c480e2b1",
            "value": " 29.0/29.0 [00:00&lt;00:00, 273B/s]"
          }
        },
        "fe733235efed485b8f4ed5324e23d6dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14df01630ac2484eb84c91f13a808eca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4363879cdd04f6a857e97e233231434": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56be7eda2ff3436ca1d3a05c0ee90ceb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe4c5844930e44de9630fc55224789a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7fc68d703ca34da6a9c0ab3668d28e3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3175deb5c7dd469d8fda0ce5c480e2b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "052297dcd4c44c1cb38d4c27f7b7b78b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1fcf88d615384f779dae7525c9597ed0",
              "IPY_MODEL_50a6d0fdcfb74c1ebf0d131ad30f80a4",
              "IPY_MODEL_6114521e1cc94f95a63b601a1890dbcd"
            ],
            "layout": "IPY_MODEL_6e33776a5cd0438fa72821e3e430412d"
          }
        },
        "1fcf88d615384f779dae7525c9597ed0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f25d31e5cfdb470889de951b1eb669c3",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a7e6f558c0b04634a2c4e29f518e169a",
            "value": "Downloading: 100%"
          }
        },
        "50a6d0fdcfb74c1ebf0d131ad30f80a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ed6b132cc8644caa3c302cb9f05cacd",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1eaef2f5690c449ead3e56db2b0ce201",
            "value": 570
          }
        },
        "6114521e1cc94f95a63b601a1890dbcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3da63190399748c3ae5d0fde86241c2e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2234004255dc429690c9b70cf50e2b99",
            "value": " 570/570 [00:00&lt;00:00, 5.48kB/s]"
          }
        },
        "6e33776a5cd0438fa72821e3e430412d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f25d31e5cfdb470889de951b1eb669c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7e6f558c0b04634a2c4e29f518e169a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ed6b132cc8644caa3c302cb9f05cacd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1eaef2f5690c449ead3e56db2b0ce201": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3da63190399748c3ae5d0fde86241c2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2234004255dc429690c9b70cf50e2b99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOnz8OxdbN3y"
      },
      "source": [
        "# Tokenization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZb_LOZr7XF_"
      },
      "source": [
        "### Data Preparation\n",
        "\n",
        "\n",
        "*   ë°ì´í„°(train, dev, test)ê°€ ì €ìž¥ëœ ë“œë¼ì´ë¸Œë¥¼ ë§ˆìš´íŠ¸í•˜ì—¬ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìžˆëŠ” ê²½ë¡œë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkCrAHWVmUck",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "001b737a-084c-444c-9555-6fd4fe3913df"
      },
      "source": [
        "import os, sys\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# í˜„ìž¬ íŒŒì¼ ê²½ë¡œì— ë§žê²Œ ì„¤ì •í•´ì£¼ì„¸ìš”.\n",
        "os.chdir('/content/drive/MyDrive/Colab_CS/[HW30] Sub-word Tokenization')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9yYsxMfyZsi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "338aa2dd-4c9b-4038-86ac-3976c28fda3c"
      },
      "source": [
        "# í˜„ìž¬ ê²½ë¡œ í™•ì¸\n",
        "!pwd"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab_CS/[HW30] Sub-word Tokenization\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceOZZ8UOU4or",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c34a97be-fe0b-4fe3-979b-5e4a8e997c46"
      },
      "source": [
        "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
        "!pip install transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.8 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.2)\n",
            "Collecting tokenizers!=0.11.3,>=0.11.1\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.5 MB 32.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 596 kB 45.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895 kB 48.0 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSNON1TAbj2i"
      },
      "source": [
        "### Introduction\n",
        "\n",
        "\n",
        "* ë³¸ ê³¼ì œì˜ ëª©ì ì€ Subword tokenizationì˜ í•„ìš”ì„±ì„ ì§ì ‘ ëŠê»´ë³´ëŠ” ê²ƒìž…ë‹ˆë‹¤.\n",
        "* Subword tokenization ê¸°ë°˜ language modelì„ êµ¬í˜„í•˜ë©´ì„œ ì´ì „ ê³¼ì œì˜ Word-level language modelê³¼ ë¹„êµí•´ë³´ëŠ” ì‹œê°„ì„ ê°–ê² ìŠµë‹ˆë‹¤. ì¶”ê°€ì ìœ¼ë¡œ RNNì„ LSTMìœ¼ë¡œ ë³€ê²½í–ˆì„ ë•Œì˜ ì„±ëŠ¥ ì°¨ì´ì— ëŒ€í•´ ì‚´íŽ´ë³´ê² ìŠµë‹ˆë‹¤.\n",
        "*   Subword-level language modelì„ êµ¬í˜„í•˜ê³ , ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ ê°€ê³µí•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµí•œ í›„ í•™ìŠµëœ ì–¸ì–´ ëª¨ë¸ì„ ì´ìš©í•´ ë¬¸ìž¥ì„ ìƒì„±í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xzSMF9RJyzg"
      },
      "source": [
        "\n",
        "```\n",
        "ðŸ’¡ SubwordëŠ” ë¬´ì—‡ì¸ê°€ìš”?\n",
        "\n",
        "SubwordëŠ” í•˜ë‚˜ì˜ ë‹¨ì–´ë¥¼ ì—¬ëŸ¬ê°œì˜ ë‹¨ìœ„ë¡œ ë¶„ë¦¬í–ˆì„ ë•Œ í•˜ë‚˜ì˜ ë‹¨ìœ„ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. \"subword\"ë¥¼ subword ë‹¨ìœ„ë¡œ ë‚˜íƒ€ë‚¸ í•˜ë‚˜ì˜ ì˜ˆì‹œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
        "\n",
        "\"sub\" + \"word\"\n",
        "\n",
        "subë¼ëŠ” ì ‘ë‘ì‚¬ì™€ wordë¼ê³  í•˜ëŠ” ì–´ê·¼ìœ¼ë¡œ ë‚˜ëˆ„ì–´ \"subword\"ë¼ê³  í•˜ëŠ” wordë¥¼ 2ê°œì˜ subwordë¡œ ë‚˜íƒ€ëƒˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "ì´ì™¸ì—ë„ ë‹¤ì–‘í•œ í˜•íƒœì˜ subwordë¡œ ë‚˜íƒ€ë‚¼ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. (e.g., \"su\" + \"bword\", \"s\" + \"ubword\", \"subwor\" + \"d\")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrgY-yRfVJON"
      },
      "source": [
        "```\n",
        "ðŸ’¡ tokenizationì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
        "\n",
        "tokenizationì€ ì£¼ì–´ì§„ ìž…ë ¥ ë°ì´í„°ë¥¼ ìžì—°ì–´ì²˜ë¦¬ ëª¨ë¸ì´ ì¸ì‹í•  ìˆ˜ ìžˆëŠ” ë‹¨ìœ„ë¡œ ë³€í™˜í•´ì£¼ëŠ” ë°©ë²•ìž…ë‹ˆë‹¤. \n",
        "\n",
        "ðŸ’¡ word tokenizationì€ìš”?\n",
        "\n",
        "word tokenizationì˜ ê²½ìš° \"ë‹¨ì–´\"ê°€ ìžì—°ì–´ì²˜ë¦¬ ëª¨ë¸ì´ ì¸ì‹í•˜ëŠ” ë‹¨ìœ„ê°€ ë©ë‹ˆë‹¤.\n",
        "\"I have a meal\"ì´ë¼ê³  í•˜ëŠ” ë¬¸ìž¥ì„ ê°€ì§€ê³  word tokenizationì„ í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. \n",
        "\n",
        "- ['I', 'have', 'a', 'meal']\n",
        "\n",
        "ì˜ì–´ì˜ ê²½ìš° ëŒ€ë¶€ë¶„ spaceë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë‹¨ì–´ê°€ ì •ì˜ë˜ê¸° ë•Œë¬¸ì— .split()ì„ ì´ìš©í•´ ì‰½ê²Œ word tokenizationì„ êµ¬í˜„í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n",
        "ì˜ì–´ì—ì„œ word tokenizationì€ space tokenizationì´ë¼ê³ ë„ í•  ìˆ˜ ìžˆê³ , \n",
        "subword tokenization ì´ì „ì— ìˆ˜í–‰ë˜ëŠ” pre-tokenization ë°©ë²•ìœ¼ë¡œë„ ë§Žì´ ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
        "\n",
        "\"ë‚˜ëŠ” ë°¥ì„ ë¨¹ëŠ”ë‹¤\"ë¼ëŠ” ë¬¸ìž¥ì„ word tokenizationí•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
        "- ['ë‚˜', 'ëŠ”', 'ë°¥', 'ì„', 'ë¨¹ëŠ”ë‹¤']\n",
        "\n",
        "í•œêµ­ì–´ì—ì„œ \"ë‹¨ì–´\"ëŠ” ê³µë°±(space)ì„ ê¸°ì¤€ìœ¼ë¡œ ì •ì˜ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì´ëŠ” í•œêµ­ì–´ê°€ ê°–ê³  ìžˆëŠ” \"êµì°©ì–´\"ë¡œì„œì˜ íŠ¹ì§• ë•Œë¬¸ìž…ë‹ˆë‹¤. \n",
        "ì²´ì–¸ ë’¤ì— ì¡°ì‚¬ê°€ ë¶™ëŠ” ê²ƒì´ ëŒ€í‘œì ì¸ íŠ¹ì§•ì´ë©° ì˜ë¯¸ ë‹¨ìœ„ê°€ êµ¬ë¶„ë˜ê³  ìžë¦½ì„±ì´ ìžˆê¸° ë•Œë¬¸ì— ì¡°ì‚¬ëŠ” \"ë‹¨ì–´\"ìž…ë‹ˆë‹¤.\n",
        "\n",
        "í•œêµ­ì–´ì—ì„œëŠ” pre-tokenization ë°©ë²•ìœ¼ë¡œ space tokenizationì„ ì‚¬ìš©í•˜ì§€ ì•Šê³  í˜•íƒœì†Œ ë¶„ì„ê¸°ë¥¼ í™œìš©í•˜ê³  ìžˆìŠµë‹ˆë‹¤.\n",
        "```\n",
        "\n",
        "(ì°¸ê³ 1: [êµ­ë¦½ êµ­ì–´ì›: \"ì¡°ì‚¬ëŠ” ë‹¨ì–´ì´ë‹¤\"](https://www.korean.go.kr/front/onlineQna/onlineQnaView.do?mn_id=216&qna_seq=26915#:~:text='%EC%A1%B0%EC%82%AC'%EB%8A%94%20%EC%99%84%EC%A0%84%ED%95%9C%20%EC%9E%90%EB%A6%BD%EC%84%B1%EC%9D%80,%ED%95%98%EC%97%AC%20%EB%8B%A8%EC%96%B4%EB%A1%9C%20%EC%B2%98%EB%A6%AC%ED%95%A9%EB%8B%88%EB%8B%A4.) )\n",
        "\n",
        "(ì°¸ê³ 2: [Huggingface: Pre-tokenization](https://huggingface.co/docs/tokenizers/python/latest/pipeline.html#pre-tokenization))\n",
        "\n",
        "(ì°¸ê³ 3: [Konlpy: í˜•íƒœì†Œ ë¶„ì„ê¸°](https://konlpy-ko.readthedocs.io/ko/v0.4.3/morph/))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVQgjQJdAbWh"
      },
      "source": [
        "```\n",
        "ðŸ’¡ ê·¸ëŸ¼ Subword tokenizationì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
        "\n",
        "Subword tokenizaitonì€ ë§ ê·¸ëŒ€ë¡œ subword ë‹¨ìœ„ë¡œ tokenizationì„ í•œë‹¤ëŠ” ëœ»ìž…ë‹ˆë‹¤.\n",
        "ë°©ê¸ˆ ì „ word tokenizationì„ ìˆ˜í–‰í–ˆë˜ ë¬¸ìž¥ì„ ì´ìš©í•´ subword tokenizationì„ ìˆ˜í–‰í•œ ì˜ˆì‹œë¥¼ ë³´ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "Subword tokenizationì„ ì ìš©í–ˆì„ ë•ŒëŠ” ë‹¤ìŒê³¼ ê°™ì´ tokenizationì´ ë  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "Example 1\n",
        "\n",
        "\"I have a meal\" -> ['I', 'hav', 'e', 'a', 'me', 'al']\n",
        "\"ë‚˜ëŠ” ë°¥ì„ ë¨¹ëŠ”ë‹¤\" -> ['ë‚˜', 'ëŠ”', 'ë°¥', 'ì„', 'ë¨¹ëŠ”', 'ë‹¤']\n",
        "\n",
        "word ë‹¨ìœ„ê°€ ì•„ë‹ˆë¼ ê·¸ë³´ë‹¤ ë” ìž˜ê²Œ ìª¼ê°  subword ë‹¨ìœ„ë¡œ ë¬¸ìž¥ì„ tokenizationí•©ë‹ˆë‹¤.\n",
        "\n",
        "ìœ„ì—ì„œ ë§ì”€ë“œë¦° ê²ƒê³¼ ê°™ì´ ì—¬ëŸ¬ê°€ì§€ ê²½ìš°ì˜ ìˆ˜ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
        "\n",
        "Example 2\n",
        "\n",
        "\"I have a meal\" -> ['I', 'ha', 've', 'a', 'mea', 'l']\n",
        "\"ë‚˜ëŠ” ë°¥ì„ ë¨¹ëŠ”ë‹¤\" -> ['ë‚˜', 'ëŠ”', 'ë°¥', 'ì„', 'ë¨¹', 'ëŠ”ë‹¤']\n",
        "\n",
        "ê·¸ë ‡ì§€ë§Œ ê¸°ë³¸ì ìœ¼ë¡œ ê³µë°±ì„ ë„˜ì–´ì„  subwordë¥¼ êµ¬ì„±í•˜ì§„ ì•ŠìŠµë‹ˆë‹¤.\n",
        "ì˜ˆë¥¼ ë“¤ì–´ ë‹¤ìŒê³¼ ê°™ì´ tokenizaitonì„ ìˆ˜í–‰í•˜ì§„ ì•ŠìŠµë‹ˆë‹¤.\n",
        "\n",
        "Example 3\n",
        "\n",
        "\"I have a meal\" -> ['Iha', 've', 'am', 'ea', 'l']\n",
        "\"ë‚˜ëŠ” ë°¥ì„ ë¨¹ëŠ”ë‹¤\" -> ['ë‚˜ëŠ”ë°¥', 'ì„ë¨¹', 'ëŠ”ë‹¤']\n",
        "```\n",
        "\n",
        "(ì°¸ê³ 4: [Huggingface: subword-tokenization](https://huggingface.co/transformers/tokenizer_summary.html#subword-tokenization))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPRNaFhMEK67"
      },
      "source": [
        "```\n",
        "ðŸ’¡ Subword tokenizationì€ ì™œ í•„ìš”í•œê°€ìš”?\n",
        "\n",
        "word tokenization ì½”ë“œë¥¼ ë¶ˆëŸ¬ì™€ ê·¸ í•„ìš”ì„±ì„ ìƒê°í•´ ë´…ì‹œë‹¤.\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DESsQzhwGVST"
      },
      "source": [
        "import os\n",
        "from io import open\n",
        "import torch"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWd09aUBGWa9"
      },
      "source": [
        "class Dictionary(object):\n",
        "    def __init__(self):\n",
        "        self.word2idx = {'<unk>': 0}\n",
        "        self.idx2word = ['<unk>']\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self.word2idx:\n",
        "            self.idx2word.append(word)\n",
        "            self.word2idx[word] = len(self.idx2word) - 1\n",
        "        return self.word2idx[word]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idx2word)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQIyGQlfd9Os"
      },
      "source": [
        "class Corpus(object):\n",
        "    def __init__(self, path):\n",
        "        self.dictionary = Dictionary()\n",
        "        \"\"\"Tokenizes a text file.\"\"\"\n",
        "        assert os.path.exists(path)\n",
        "        # Add words to the dictionary\n",
        "        with open(os.path.join(path, 'train.txt'), 'r', encoding=\"utf8\") as f:\n",
        "            for line in f:\n",
        "                words = line.split() + ['<eos>']\n",
        "                for word in words:\n",
        "                    self.dictionary.add_word(word)\n",
        "\n",
        "        self.train = self.tokenize(os.path.join(path, 'train.txt'))\n",
        "        self.valid = self.tokenize(os.path.join(path, 'valid.txt'))\n",
        "        self.test = self.tokenize(os.path.join(path, 'test.txt'))\n",
        "\n",
        "    def tokenize(self, path):\n",
        "        # Tokenize file content\n",
        "        with open(path, 'r', encoding=\"utf8\") as f:\n",
        "            idss = []\n",
        "            for line in f:\n",
        "                words = line.split() + ['<eos>']\n",
        "                ids = []\n",
        "                for word in words:\n",
        "                    try:\n",
        "                        ids.append(self.dictionary.word2idx[word])\n",
        "                    except:\n",
        "                        print(word)\n",
        "                        ids.append(0)\n",
        "                idss.append(torch.tensor(ids).type(torch.int64))\n",
        "            ids = torch.cat(idss)\n",
        "\n",
        "        return ids"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a55D0z53eLzB"
      },
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class RNNModel(nn.Module):\n",
        "    \"\"\"Container module with an encoder, a recurrent module, and a decoder.\"\"\"\n",
        "\n",
        "    def __init__(self, rnn_type, ntoken, ninp, nhid, nlayers, dropout=0.5):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.ntoken = ntoken\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.encoder = nn.Embedding(ntoken, ninp)\n",
        "        if rnn_type in ['LSTM', 'GRU']:\n",
        "            self.rnn = getattr(nn, rnn_type)(ninp, nhid, nlayers, dropout=dropout)\n",
        "        else:\n",
        "            try:\n",
        "                nonlinearity = {'RNN_TANH': 'tanh', 'RNN_RELU': 'relu'}[rnn_type]\n",
        "            except KeyError:\n",
        "                raise ValueError( \"\"\"An invalid option for `--model` was supplied,\n",
        "                                 options are ['LSTM', 'GRU', 'RNN_TANH' or 'RNN_RELU']\"\"\")\n",
        "            self.rnn = nn.RNN(ninp, nhid, nlayers, nonlinearity=nonlinearity, dropout=dropout)\n",
        "        self.decoder = nn.Linear(nhid, ntoken)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "        self.rnn_type = rnn_type\n",
        "        self.nhid = nhid\n",
        "        self.nlayers = nlayers\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        nn.init.uniform_(self.encoder.weight, -initrange, initrange)\n",
        "        nn.init.zeros_(self.decoder.weight)\n",
        "        nn.init.uniform_(self.decoder.weight, -initrange, initrange)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        emb = self.drop(self.encoder(input))\n",
        "        output, hidden = self.rnn(emb, hidden)\n",
        "        output = self.drop(output)\n",
        "        decoded = self.decoder(output)\n",
        "        decoded = decoded.view(-1, self.ntoken)\n",
        "        return F.log_softmax(decoded, dim=1), hidden\n",
        "\n",
        "    def init_hidden(self, bsz):\n",
        "        weight = next(self.parameters())\n",
        "        if self.rnn_type == 'LSTM':\n",
        "            return (weight.new_zeros(self.nlayers, bsz, self.nhid),\n",
        "                    weight.new_zeros(self.nlayers, bsz, self.nhid))\n",
        "        else:\n",
        "            return weight.new_zeros(self.nlayers, bsz, self.nhid)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDQTvkdJdZOk"
      },
      "source": [
        "import time\n",
        "import math\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import easydict\n",
        "args = easydict.EasyDict({\n",
        "    \"data\"    : './data/wikitext-2',    # location of the data corpus\n",
        "    \"model\"   : 'RNN_TANH',             # type of recurrent net (RNN_TANH, RNN_RELU, LSTM, GRU)\n",
        "    \"emsize\"  : 200,                    # size of word embeddings\n",
        "    \"nhid\"    : 512,                    # number of hidden units per layer\n",
        "    \"nlayers\" : 2,                      # number of layers\n",
        "    \"lr\"      : 20,                     # initial learning rate\n",
        "    \"clip\"    : 0.25,                   # gradient clipping\n",
        "    \"epochs\"  : 6,                      # upper epoch limit\n",
        "    \"batch_size\": 20,                   # batch size\n",
        "    \"bptt\"    : 35,                     # sequence length\n",
        "    \"dropout\" : 0.2,                    # dropout applied to layers (0 = no dropout)\n",
        "    \"seed\"    : 1111,                   # random seed\n",
        "    \"cuda\"    : True,                   # use CUDA\n",
        "    \"log_interval\": 200,                # report interval\n",
        "    \"save\"    : 'model.pt',             # path to save the final model\n",
        "    \"dry_run\" : True,                   # verify the code and the model\n",
        "\n",
        "})\n",
        "\n",
        "# ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
        "device = torch.device(\"cuda\" if args.cuda else \"cpu\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnsZkQqUHb6Z"
      },
      "source": [
        "```\n",
        "train.txtì˜ ë¬¸ìž¥ë“¤ì„ word tokenization í•´ë³´ê³  ë‹¨ì–´ë“¤ì˜ ê°œìˆ˜ë¥¼ ì„¸ì–´ë³´ê² ìŠµë‹ˆë‹¤\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aSB9Hk4HjyO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d167d908-1f22-44e8-bb4e-81c1d0c66023"
      },
      "source": [
        "corpus = Corpus('./data/wikitext-2')\n",
        "ntokens = len(corpus.dictionary)\n",
        "print(ntokens)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33278\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBkvRpEcKEvd"
      },
      "source": [
        "```\n",
        "ì´ì „ ê³¼ì œì— ì‚¬ìš©ëœ embedding dimensionì˜ í¬ê¸°ëŠ” 200ì´ë¯€ë¡œ word embeddingì— ì‚¬ìš©ëœ parameterì˜ ìˆ˜ëŠ” 33278 x 200 (6,655,600ê°œ)ìž…ë‹ˆë‹¤.\n",
        "\n",
        "ê·¸ë ‡ë‹¤ë©´, RNN ëª¨ë¸ì— ì‚¬ìš©ë˜ëŠ” weightì˜ parameter ê°œìˆ˜ëŠ” ëª‡ê°œì¸ì§€ ê°„ë‹¨í•œ í•¨ìˆ˜ë¥¼ ì´ìš©í•´ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGjG2j-fKbJu"
      },
      "source": [
        "model = RNNModel(args.model, ntokens, args.emsize, args.nhid, args.nlayers, args.dropout)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTiKccVXLrvx"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvRPOxLCLByf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3331d513-cd5c-45b9-e640-438f5d8288b3"
      },
      "source": [
        "print(f\"Word embedding parameter ê°œìˆ˜: {count_parameters(model.encoder)}\")\n",
        "print(f\"RNN parameter ê°œìˆ˜: {count_parameters(model.rnn)}\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word embedding parameter ê°œìˆ˜: 6655600\n",
            "RNN parameter ê°œìˆ˜: 890880\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlUFvgTNM1Od"
      },
      "source": [
        "```\n",
        "ðŸ’¡ RNN parameter, Word embedding parameter ê°œìˆ˜ë¥¼ ë¹„êµí•´ë³´ë©´ word embedding parameterì˜ ê°œìˆ˜ê°€ RNN ëª¨ë¸ì˜ parameterë³´ë‹¤ ì••ë„ì ìœ¼ë¡œ ë§ŽìŠµë‹ˆë‹¤.\n",
        "\n",
        "word embeddingì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš° trainingì— ì‚¬ìš©ë˜ëŠ” text fileì˜ í¬ê¸°ê°€ ì»¤ì§ˆìˆ˜ë¡ word embedding parameterëŠ” \n",
        "ë” ì»¤ì§€ê²Œ ë˜ê³  ì „ì²´ parameter ëŒ€ë¹„ word embeddingì´ ì°¨ì§€í•˜ëŠ” ë¹„ì¤‘ì€ ë§¤ìš° ë†’ì•„ì§‘ë‹ˆë‹¤.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7WfyYBrPpca"
      },
      "source": [
        "```\n",
        "âœ¨ ì´ëŸ° parameter ë¹„ì¤‘ì˜ ë¹„ëŒ€ì¹­ì„±ì„ í•´ê²°í•˜ê¸° ìœ„í•´ ì²˜ìŒì—ëŠ” character-level tokenization ë°©ë²•ì´ ì£¼ëª©ì„ ë°›ì•˜ìŠµë‹ˆë‹¤. \n",
        "ë§ ê·¸ëŒ€ë¡œ í•˜ë‚˜ì˜ ê¸€ìžë¥¼ ê¸°ì¤€ìœ¼ë¡œ tokenizationì„ í•˜ëŠ”ê±´ë°ìš”.\n",
        "ì´ì „ ì˜ˆì‹œë¥¼ character ê¸°ë°˜ tokenizationì„ í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
        "\n",
        "\"I have a meal\" -> ['I', 'h', 'a', 'v', 'e', 'a', 'm', 'e', 'a', 'l']\n",
        "\"ë‚˜ëŠ” ë°¥ì„ ë¨¹ëŠ”ë‹¤\" -> ['ë‚˜', 'ëŠ”', 'ë°¥', 'ì„', 'ë¨¹', 'ëŠ”', 'ë‹¤']\n",
        "\n",
        "ê·¸ëŸ¬ë‚˜, character ê¸°ë°˜ tokenization ì—­ì‹œ ì§€ë‚˜ì¹˜ê²Œ ê¸´ sequence ê¸¸ì´, ì„±ëŠ¥ ì €í•˜ ë“±ì˜ ë¬¸ì œë¥¼ ê²ªìœ¼ë©° \n",
        "subword tokenizationì´ ê°ê´‘ì„ ë°›ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "â“ word tokenization ê¸°ë²•ê³¼ êµ¬ë¶„ë˜ëŠ” subword tokenizationì˜ ìž¥ì ì„ í•˜ë‚˜ë§Œ ë” ìƒê°í•´ë³¼ê¹Œìš”?\n",
        "\n",
        "subword tokenizationì˜ ìž¥ì ì€ Out-of-vocabulary (OOV) ë¬¸ì œì—ì„œ ìƒëŒ€ì ìœ¼ë¡œ ìžìœ ë¡­ë‹¤ëŠ” ê²ƒìž…ë‹ˆë‹¤.\n",
        "\n",
        "ì¼ë°˜ì ìœ¼ë¡œ subwordë“¤ì€ ìµœì†Œ ì² ìž ë‹¨ìœ„ì—ì„œ í•˜ë‚˜ì”© ë” ê¸´ subwordë¥¼ ì¶”ê°€í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ë§Œë“¤ì–´ì§‘ë‹ˆë‹¤.\n",
        "\n",
        "ì˜ˆë¥¼ ë“¤ì–´, ì˜ì–´ì˜ ê²½ìš° a~zì˜ ì•ŒíŒŒë²³ë¶€í„° ì‹œìž‘í•´ì„œ ë‘ê¸€ìž, ì„¸ê¸€ìž, ë„¤ê¸€ìž subword ë“±ìœ¼ë¡œ í™•ìž¥í•´ë‚˜ê°€ë©° \n",
        "subwordë¥¼ ì¶”ê°€í•´ ë‹¨ì–´ë¥¼ êµ¬ì„±í•˜ê³  ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ subword tokenizationì„ ìˆ˜í–‰í•˜ê¸° ë•Œë¬¸ì— ë‹¤ë¥¸ ì–¸ì–´ë¥¼ tokenizationí•˜ì§€ ì•ŠëŠ”ë‹¤ë©´ \n",
        "OOV ë¬¸ì œì—ì„œ ìžìœ ë¡­ë‹¤ê³  ë³¼ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "ëŒ€í‘œì ì¸ subword tokenizationì— ì‚¬ìš©ë˜ëŠ” algorithm ì¤‘ í•˜ë‚˜ì¸ byte pair encodingì€ ì„ íƒ ê³¼ì œ 3ì—ì„œ ì‚´íŽ´ë³¼ ìˆ˜ ìžˆìœ¼ë‹ˆ ì°¸ê³ í•´ì£¼ì„¸ìš” !\n",
        "\n",
        "âœ¨ ê·¸ëŸ¼ ì´ì œë¶€í„° BERT ëª¨ë¸ì—ì„œ ì‚¬ìš©í•œ subword tokenization algorithmì„ ì´ìš©í•´ language modeling taskë¥¼ ìˆ˜í–‰í•´ë³´ê² ìŠµë‹ˆë‹¤. \n",
        "subword tokenizerëŠ” transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì´ìš©í•´ ì‰½ê²Œ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n",
        "```\n",
        "\n",
        "(ì°¸ê³ 5: [Huggingface: subword tokenization](https://huggingface.co/transformers/tokenizer_summary.html#subword-tokenization))\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZKyn3PKUuBg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "961c0ac8c25949218f8e52c4be6f8123",
            "d4b20bb9be864d10beabad038d8df23c",
            "9908a709076c479183e9457ab199ca8f",
            "528248a7e0d24d50852e7167b9bdb6f6",
            "047898783c5a4dbc80a77f2505656fa8",
            "c263236ed5524bc5986ac446bdcc2073",
            "6d619529fe3e47eb84461cf6ba89d7e2",
            "807a3da61af44ae48c6649f3d90f38e8",
            "08781f1880834f73b147d582ee53ffb0",
            "8a5a6e93d1784ac395e588ca7a0e8dec",
            "b4e0708ff88946e2928002506df1dbb1",
            "22f02c53f39c4f00940c5f9ac2fd2cd2",
            "868c42721968460ba5f898857582dce0",
            "37d067cca40444fe8768b90793a405c6",
            "9818b6c7fda145938d545f01450a776f",
            "fe733235efed485b8f4ed5324e23d6dc",
            "14df01630ac2484eb84c91f13a808eca",
            "f4363879cdd04f6a857e97e233231434",
            "56be7eda2ff3436ca1d3a05c0ee90ceb",
            "fe4c5844930e44de9630fc55224789a0",
            "7fc68d703ca34da6a9c0ab3668d28e3a",
            "3175deb5c7dd469d8fda0ce5c480e2b1",
            "052297dcd4c44c1cb38d4c27f7b7b78b",
            "1fcf88d615384f779dae7525c9597ed0",
            "50a6d0fdcfb74c1ebf0d131ad30f80a4",
            "6114521e1cc94f95a63b601a1890dbcd",
            "6e33776a5cd0438fa72821e3e430412d",
            "f25d31e5cfdb470889de951b1eb669c3",
            "a7e6f558c0b04634a2c4e29f518e169a",
            "0ed6b132cc8644caa3c302cb9f05cacd",
            "1eaef2f5690c449ead3e56db2b0ce201",
            "3da63190399748c3ae5d0fde86241c2e",
            "2234004255dc429690c9b70cf50e2b99"
          ]
        },
        "outputId": "d6ce28f5-ca9f-4a89-b715-d9bd00f9dcbd"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "961c0ac8c25949218f8e52c4be6f8123"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "22f02c53f39c4f00940c5f9ac2fd2cd2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "052297dcd4c44c1cb38d4c27f7b7b78b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwubp25xVUt2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44aba0a5-41e4-4fc2-a358-0374316e3883"
      },
      "source": [
        "# subword tokenization ì˜ˆì‹œ\n",
        "print(tokenizer.tokenize('Natural language expert training course'))\n",
        "print(tokenizer.tokenize('Goorm X KAIST'))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Natural', 'language', 'expert', 'training', 'course']\n",
            "['Go', '##orm', 'X', 'K', '##A', '##IS', '##T']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLfVolP3UKos"
      },
      "source": [
        "class Corpus(object):\n",
        "    def __init__(self, path):\n",
        "        self.dictionary = Dictionary()\n",
        "        self.train = self.tokenize(os.path.join(path, 'train.txt'))\n",
        "        self.valid = self.tokenize(os.path.join(path, 'valid.txt'))\n",
        "        self.test = self.tokenize(os.path.join(path, 'test.txt'))\n",
        "\n",
        "    def tokenize(self, path):\n",
        "        assert os.path.exists(path)\n",
        "        # Add words to the dictionary\n",
        "        with open(path, 'r', encoding=\"utf8\") as f:\n",
        "            for line in f:\n",
        "                words = tokenizer.tokenize(line.strip()) + ['<eos>']\n",
        "                for word in words:\n",
        "                    self.dictionary.add_word(word)\n",
        "\n",
        "        # Tokenize file content\n",
        "        with open(path, 'r', encoding=\"utf8\") as f:\n",
        "            idss = []\n",
        "            for line in f:\n",
        "                words = tokenizer.tokenize(line.strip()) + ['<eos>']\n",
        "                ids = []\n",
        "                for word in words:\n",
        "                    ids.append(self.dictionary.word2idx[word])\n",
        "                idss.append(torch.tensor(ids).type(torch.int64))\n",
        "            ids = torch.cat(idss)\n",
        "\n",
        "        return ids"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvtarB2DYiLb"
      },
      "source": [
        "```\n",
        "ê·¸ëŸ¬ë©´ ì´ì œ ë‹¤ì‹œ ëª¨ë¸ì„ ì„ ì–¸í•˜ê³  parameterì˜ ê°œìˆ˜ë¥¼ ì‚´íŽ´ë³´ê² ìŠµë‹ˆë‹¤.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLKqis0hY5Or"
      },
      "source": [
        "subword_corpus = Corpus('./data/wikitext-2')\n",
        "ntokens = len(subword_corpus.dictionary)\n",
        "subwordmodel = RNNModel(args.model, ntokens, args.emsize, args.nhid, args.nlayers, args.dropout)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RB4DQ-QZCBd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0881aa35-5fce-4454-dbaf-6a993e4ca969"
      },
      "source": [
        "print(f\"Word embedding parameter ê°œìˆ˜: {count_parameters(subwordmodel.encoder)}\")\n",
        "print(f\"RNN parameter ê°œìˆ˜: {count_parameters(subwordmodel.rnn)}\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word embedding parameter ê°œìˆ˜: 4619000\n",
            "RNN parameter ê°œìˆ˜: 890880\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_5y4M6k1HR6"
      },
      "source": [
        "```\n",
        "ì´ì „ì— ë¹„í•´ embedding parameter ê°œìˆ˜ëŠ” í™•ì—°ížˆ ì¤„ì–´ë“¤ì—ˆìŠµë‹ˆë‹¤.\n",
        "6,655,600ê°œ -> 4,619,000ê°œ\n",
        "\n",
        "ê·¸ëŸ¬ë©´ ì´ì œ subword ê¸°ë°˜ì˜ ì–¸ì–´ ëª¨ë¸ ì„±ëŠ¥ì„ ì‚´íŽ´ë³´ê² ìŠµë‹ˆë‹¤.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlSdSCKvd23M"
      },
      "source": [
        "###############################################################################\n",
        "# Load data\n",
        "###############################################################################\n",
        "\n",
        "# Starting from sequential data, batchify arranges the dataset into columns.\n",
        "# For instance, with the alphabet as the sequence and batch size 4, we'd get\n",
        "# â”Œ a g m s â”\n",
        "# â”‚ b h n t â”‚\n",
        "# â”‚ c i o u â”‚\n",
        "# â”‚ d j p v â”‚\n",
        "# â”‚ e k q w â”‚\n",
        "# â”” f l r x â”˜.\n",
        "# These columns are treated as independent by the model, which means that the\n",
        "# dependence of e. g. 'g' on 'f' can not be learned, but allows more efficient\n",
        "# batch processing.\n",
        "\n",
        "def batchify(data, bsz):\n",
        "    # Work out how cleanly we can divide the dataset into bsz parts.\n",
        "    nbatch = data.size(0) // bsz\n",
        "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
        "    data = data.narrow(0, 0, nbatch * bsz)\n",
        "    # Evenly divide the data across the bsz batches.\n",
        "    data = data.view(bsz, -1).t().contiguous()\n",
        "    return data.to(device)\n",
        "\n",
        "eval_batch_size = 10\n",
        "train_data = batchify(subword_corpus.train, args.batch_size)\n",
        "val_data = batchify(subword_corpus.valid, eval_batch_size)\n",
        "test_data = batchify(subword_corpus.test, eval_batch_size)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7iRv2rHe959"
      },
      "source": [
        "###############################################################################\n",
        "# Build the model\n",
        "###############################################################################\n",
        "\n",
        "model = RNNModel(args.model, ntokens, args.emsize, args.nhid, args.nlayers, args.dropout).to(device)\n",
        "criterion = nn.NLLLoss()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiLaw_Bte_nJ"
      },
      "source": [
        "###############################################################################\n",
        "# Training code1 - define functions\n",
        "###############################################################################\n",
        "\n",
        "def repackage_hidden(h):\n",
        "    \"\"\"Wraps hidden states in new Tensors, to detach them from their history.\"\"\"\n",
        "\n",
        "    if isinstance(h, torch.Tensor):\n",
        "        return h.detach()\n",
        "    else:\n",
        "        return tuple(repackage_hidden(v) for v in h)\n",
        "\n",
        "\n",
        "# get_batch subdivides the source data into chunks of length args.bptt.\n",
        "# If source is equal to the example output of the batchify function, with\n",
        "# a bptt-limit of 2, we'd get the following two Variables for i = 0:\n",
        "# â”Œ a g m s â” â”Œ b h n t â”\n",
        "# â”” b h n t â”˜ â”” c i o u â”˜\n",
        "# Note that despite the name of the function, the subdivison of data is not\n",
        "# done along the batch dimension (i.e. dimension 1), since that was handled\n",
        "# by the batchify function. The chunks are along dimension 0, corresponding\n",
        "# to the seq_len dimension in the LSTM.\n",
        "\n",
        "def get_batch(source, i):\n",
        "    seq_len = min(args.bptt, len(source) - 1 - i)\n",
        "    data = source[i:i+seq_len]\n",
        "    target = source[i+1:i+1+seq_len].view(-1)\n",
        "    return data, target\n",
        "\n",
        "\n",
        "def evaluate(data_source):\n",
        "    # Turn on evaluation mode which disables dropout.\n",
        "    model.eval()\n",
        "    total_loss = 0.\n",
        "    ntokens = len(subword_corpus.dictionary)\n",
        "    hidden = model.init_hidden(eval_batch_size)\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, data_source.size(0) - 1, args.bptt):\n",
        "            data, targets = get_batch(data_source, i)\n",
        "            output, hidden = model(data, hidden)\n",
        "            hidden = repackage_hidden(hidden)\n",
        "            total_loss += len(data) * criterion(output, targets).item()\n",
        "    return total_loss / (len(data_source) - 1)\n",
        "\n",
        "\n",
        "def train():\n",
        "    # Turn on training mode which enables dropout.\n",
        "    model.train()\n",
        "    total_loss = 0.\n",
        "    start_time = time.time()\n",
        "    ntokens = len(subword_corpus.dictionary)\n",
        "    hidden = model.init_hidden(args.batch_size)\n",
        "    for batch, i in enumerate(range(0, train_data.size(0) - 1, args.bptt)):\n",
        "        data, targets = get_batch(train_data, i)\n",
        "        # Starting each batch, we detach the hidden state from how it was previously produced.\n",
        "        # If we didn't, the model would try backpropagating all the way to start of the dataset.\n",
        "        model.zero_grad()\n",
        "\n",
        "        hidden = repackage_hidden(hidden)\n",
        "        output, hidden = model(data, hidden)\n",
        "\n",
        "        loss = criterion(output, targets)\n",
        "        loss.backward()\n",
        "\n",
        "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
        "        for p in model.parameters():\n",
        "            p.data.add_(p.grad, alpha=-lr)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        if batch % args.log_interval == 0 and batch > 0:\n",
        "            cur_loss = total_loss / args.log_interval\n",
        "            elapsed = time.time() - start_time\n",
        "            print('| epoch {:3d} | {:5d}/{:5d} batches | lr {:02.2f} | ms/batch {:5.2f} | '\n",
        "                    'loss {:5.2f} | ppl {:8.2f}'.format(\n",
        "                epoch, batch, len(train_data) // args.bptt, lr,\n",
        "                elapsed * 1000 / args.log_interval, cur_loss, math.exp(cur_loss)))\n",
        "            total_loss = 0\n",
        "            start_time = time.time()\n",
        "        if args.dry_run:\n",
        "            break"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6m-cdbm7PvS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83bd79ca-c298-4f7f-a6f4-28897b029b19"
      },
      "source": [
        "###############################################################################\n",
        "# Training code2 - run \n",
        "###############################################################################\n",
        "\n",
        "# Loop over epochs.\n",
        "lr = args.lr\n",
        "best_val_loss = None\n",
        "\n",
        "# At any point you can hit Ctrl + C to break out of training early.\n",
        "try:\n",
        "    for epoch in range(1, args.epochs+1):\n",
        "        epoch_start_time = time.time()\n",
        "        train()\n",
        "        val_loss = evaluate(val_data)\n",
        "        print('-' * 89)\n",
        "        print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n",
        "                'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
        "                                           val_loss, math.exp(val_loss)))\n",
        "        print('-' * 89)\n",
        "        # Save the model if the validation loss is the best we've seen so far.\n",
        "        if not best_val_loss or val_loss < best_val_loss:\n",
        "            with open(args.save, 'wb') as f:\n",
        "                torch.save(model, f)\n",
        "            best_val_loss = val_loss\n",
        "        else:\n",
        "            # Anneal the learning rate if no improvement has been seen in the validation dataset.\n",
        "            lr /= 4.0\n",
        "except KeyboardInterrupt:\n",
        "    print('-' * 89)\n",
        "    print('Exiting from training early')\n",
        "\n",
        "# Load the best saved model.\n",
        "with open(args.save, 'rb') as f:\n",
        "    model = torch.load(f)\n",
        "    # after load the rnn params are not a continuous chunk of memory\n",
        "    # this makes them a continuous chunk, and will speed up forward pass\n",
        "    # Currently, only rnn model supports flatten_parameters function.\n",
        "    if args.model in ['RNN_TANH', 'RNN_RELU', 'LSTM', 'GRU']:\n",
        "        model.rnn.flatten_parameters()\n",
        "\n",
        "# Run on test data.\n",
        "test_loss = evaluate(test_data)\n",
        "print('=' * 89)\n",
        "print('| End of training | test loss {:5.2f} | test ppl {:8.2f}'.format(\n",
        "    test_loss, math.exp(test_loss)))\n",
        "print('=' * 89)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   1 | time:  8.17s | valid loss  8.73 | valid ppl  6214.87\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   2 | time:  7.83s | valid loss 13.56 | valid ppl 773697.34\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   3 | time:  7.86s | valid loss 12.14 | valid ppl 187067.00\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   4 | time:  7.81s | valid loss 10.47 | valid ppl 35099.39\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   5 | time:  7.81s | valid loss  9.90 | valid ppl 19869.34\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   6 | time:  7.82s | valid loss  9.77 | valid ppl 17536.80\n",
            "-----------------------------------------------------------------------------------------\n",
            "=========================================================================================\n",
            "| End of training | test loss  8.66 | test ppl  5791.99\n",
            "=========================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpv4N8wl4w8p"
      },
      "source": [
        "### 4. í•™ìŠµí•œ ì–¸ì–´ ëª¨ë¸ë¡œ ë¬¸ìž¥ ìƒì„±\n",
        "\n",
        "\n",
        "*   í•™ìŠµì´ ì™„ë£Œëœ ëª¨ë¸ì„ ë¶ˆëŸ¬ì™€ random í•œ ë‹¨ì–´ë¥¼ input ìœ¼ë¡œ ë„£ì–´ì¤€ í›„ ì •í•´ì§„ ê°œìˆ˜ì˜ ë‹¨ì–´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
        "*   ìƒì„±í•œ ë¬¸ìž¥ì„ decode í•˜ì—¬ (ì¦‰, idx2word ë¥¼ ì´ìš©í•´ id ë¥¼ word ë¡œ ë³€í™˜í•˜ì—¬) generate.txt íŒŒì¼ì— ì €ìž¥í•©ë‹ˆë‹¤.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQjeaKjO4JAh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b704826f-430c-4aa8-eeb4-bdbfd4f703e9"
      },
      "source": [
        "###############################################################################\n",
        "# Language Modeling on Wikitext-2\n",
        "#\n",
        "# This file generates new sentences sampled from the language model\n",
        "#\n",
        "###############################################################################\n",
        "\n",
        "import torch\n",
        "\n",
        "# Model parameters.\n",
        "test_args = easydict.EasyDict({\n",
        "    \"data\"      : './data/wikitext-2',  # location of data corpus\n",
        "    \"checkpoint\": './model.pt',         # model checkpoint to use\n",
        "    \"outf\"      : 'generate.txt',       # output file for generated text\n",
        "    \"words\"     : 1000,                 # number of words to generate\n",
        "    \"seed\"      : 1111,                 # random seed\n",
        "    \"cuda\"      : True,                 # use CUDA\n",
        "    \"temperature\": 1.0,                 # temperature - higher will increase diversity\n",
        "    \"log_interval\": 100                 # reporting interval\n",
        "})\n",
        "\n",
        "# Set the random seed manually for reproducibility.\n",
        "torch.manual_seed(test_args.seed)\n",
        "if torch.cuda.is_available():\n",
        "    if not test_args.cuda:\n",
        "        print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
        "\n",
        "device = torch.device(\"cuda\" if test_args.cuda else \"cpu\")\n",
        "\n",
        "if test_args.temperature < 1e-3:\n",
        "    parser.error(\"--temperature has to be greater or equal 1e-3\")\n",
        "\n",
        "with open(test_args.checkpoint, 'rb') as f:\n",
        "    model = torch.load(f).to(device)\n",
        "model.eval()\n",
        "\n",
        "# corpus = Corpus(test_args.data)\n",
        "# ntokens = len(subword_corpus.dictionary)\n",
        "\n",
        "hidden = model.init_hidden(1)\n",
        "input = torch.randint(ntokens, (1, 1), dtype=torch.long).to(device)\n",
        "\n",
        "with open(test_args.outf, 'w') as outf:\n",
        "    with torch.no_grad():  # no tracking history\n",
        "        for i in range(test_args.words):\n",
        "            output, hidden = model(input, hidden)\n",
        "            word_weights = output.squeeze().div(test_args.temperature).exp().cpu()\n",
        "            word_idx = torch.multinomial(word_weights, 1)[0]\n",
        "            input.fill_(word_idx)\n",
        "\n",
        "            word = subword_corpus.dictionary.idx2word[word_idx]\n",
        "\n",
        "            outf.write(word + ('\\n' if i % 20 == 19 else ' '))\n",
        "\n",
        "            if i % test_args.log_interval == 0:\n",
        "                print('| Generated {}/{} words'.format(i, test_args.words))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Generated 0/1000 words\n",
            "| Generated 100/1000 words\n",
            "| Generated 200/1000 words\n",
            "| Generated 300/1000 words\n",
            "| Generated 400/1000 words\n",
            "| Generated 500/1000 words\n",
            "| Generated 600/1000 words\n",
            "| Generated 700/1000 words\n",
            "| Generated 800/1000 words\n",
            "| Generated 900/1000 words\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqLfZB-1wHHK"
      },
      "source": [
        "## Reference\n",
        "[Pytorch Language Model](https://github.com/pytorch/examples/tree/master/word_language_model)\n"
      ]
    }
  ]
}